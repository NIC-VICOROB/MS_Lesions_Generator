{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "import nibabel as nib\n",
    "import matplotlib.pyplot as plt\n",
    "\n",
    "from extraction import extract_patches\n",
    "from reconstruction import perform_voting, generate_indexes\n",
    "\n",
    "from model import Multimodel"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "from keras import backend as K\n",
    "import tensorflow as tf\n",
    "config_tf = tf.ConfigProto()\n",
    "config_tf.gpu_options.allow_growth=True\n",
    "K.set_session(tf.Session(config=config_tf))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "def computing_usefull_paches(img_filename, curr_patch_shape, step, threshold):        \n",
    "    img = nib.load(img_filename).get_data()    \n",
    "    img=np.rollaxis(img,2,0)        \n",
    "    mask_patches = extract_patches(img!=0, (1, )+ curr_patch_shape  , (1, )+ step)    \n",
    "    useful_patches = np.sum(mask_patches, axis=(1, 2, 3)) > threshold       \n",
    "    del mask_patches\n",
    "    return  useful_patches"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false,
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "import os\n",
    "import sys\n",
    "import nibabel as nib\n",
    "%matplotlib inline\n",
    "\n",
    "\n",
    "#dataset path\n",
    "dataset_path = '/home/mostafasalem/AllData/New_Generator_VH_ISBI/training'\n",
    "\n",
    "#Masks patterns\n",
    "mask_pattern = dataset_path+'/{0}/W{1}.nii.gz'\n",
    "num_masks=8\n",
    "\n",
    "#Images patterns\n",
    "basalImg_pattern  = dataset_path+'/{0}/{1}_normalized_filled_WMHIM_smoothed.nii.gz'\n",
    "followupImg_pattern= dataset_path+'/{0}/{1}_normalized.nii.gz' \n",
    "\n",
    "#Modalities &Step size & Patch shape\n",
    "#modalities=['t1','t2','pd','flair']\n",
    "#modalities=['T1', 'FLAIR']\n",
    "modalities=['t1', 'flair']\n",
    "\n",
    "step = (32, 32)\n",
    "curr_patch_shape = (64, 64)\n",
    "\n",
    "#Lesions and healthy cases\n",
    "training_patients = sorted([f for f in os.listdir(dataset_path)])    \n",
    "\n",
    "#Train in&out data\n",
    "in_train={}\n",
    "out_train={}\n",
    "\n",
    "for m in modalities:\n",
    "    in_train[m] = np.empty((0, 9, ) + curr_patch_shape)\n",
    "    out_train[m] = np.empty((0, 1, ) + curr_patch_shape)\n",
    "\n",
    "#Patches threshold\n",
    "threshold = np.int32(0.0 * np.prod(curr_patch_shape[:]))\n",
    "\n",
    "#Reading the images\n",
    "for p in training_patients:\n",
    "    print 'Reading case No. {} :'.format(p)\n",
    "    \n",
    "    #Computing the usefull patches\n",
    "    print '\\tComputing the usefull paches'\n",
    "    useful_patches = computing_usefull_paches(basalImg_pattern.format(p,'t1'), curr_patch_shape, step, threshold)    \n",
    "    N = np.sum(useful_patches)\n",
    "    \n",
    "    # Reading the basal mask(s) that will be added as a second channel to all the modality encoders    \n",
    "    allmasks_patches = np.empty((N, 8, ) + curr_patch_shape)\n",
    "    print '\\tExtracting the mask patches'\n",
    "    for m in range(1,num_masks+1):        \n",
    "        mask_filename = mask_pattern.format(p,m)\n",
    "        mask = nib.load(mask_filename).get_data()\n",
    "        mask=np.rollaxis(mask,2,0)\n",
    "        mask_patches = extract_patches(mask, (1, ) + curr_patch_shape, (1, ) + step)        \n",
    "        mask_patches = mask_patches[useful_patches].reshape((-1, ) + curr_patch_shape)        \n",
    "        allmasks_patches[:, m-1] = mask_patches\n",
    "    del mask_patches\n",
    "    # The modalities encoder\n",
    "    print '\\tExtracting the modalities patches'\n",
    "    for m in modalities:\n",
    "        #Reading the basal modalities\n",
    "        print '\\t{0} basal patches'.format(m)\n",
    "        basalImg_filename = basalImg_pattern.format(p, m)\n",
    "        basalImg = nib.load(basalImg_filename).get_data()    \n",
    "        basalImg=np.rollaxis(basalImg,2,0)                \n",
    "        #basalImg = (basalImg - basalImg.mean()) / basalImg.std()    \n",
    "        modality_patches = extract_patches(basalImg, (1, ) + curr_patch_shape, (1, ) + step)\n",
    "        modality_patches = modality_patches[useful_patches].reshape((-1, 1, ) + curr_patch_shape)        \n",
    "        in_train[m] = np.vstack((np.hstack((modality_patches, allmasks_patches)), in_train[m]))               \n",
    "        del modality_patches\n",
    "    del allmasks_patches\n",
    "    \n",
    "    for m in modalities:    \n",
    "        #Reading the followup modalities\n",
    "        print '\\t{0} followup patches'.format(m)\n",
    "        followupImg_filename = followupImg_pattern.format(p, m)\n",
    "        followupImg = nib.load(followupImg_filename).get_data()    \n",
    "        followupImg=np.rollaxis(followupImg,2,0)            \n",
    "        #followupImg = (followupImg - followupImg.mean()) / followupImg.std()    \n",
    "        modality_patches = extract_patches(followupImg, (1, ) + curr_patch_shape, (1, ) + step)\n",
    "        modality_patches = modality_patches[useful_patches].reshape((-1, 1, ) + curr_patch_shape)        \n",
    "        out_train[m] = np.vstack((modality_patches, out_train[m]))\n",
    "        del modality_patches        \n",
    "    \n",
    "    print    \n",
    "print\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false,
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "print \"Inputs\"\n",
    "for key in in_train:\n",
    "    print \"Size of input modality {} :\".format(key)\n",
    "    print in_train[key].shape\n",
    "    \n",
    "print\n",
    "print \"Outputs\"\n",
    "for key in out_train:\n",
    "    print \"Size of output modality {} :\".format(key)\n",
    "    print out_train[key].shape\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false,
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "curr_patch_shape = (64, 64)\n",
    "input_modalities = ['T1', 'FLAIR']\n",
    "output_modalities = ['T1_Gen', 'FLAIR_Gen']\n",
    "output_weights = {'T1_Gen' :1.0 ,'FLAIR_Gen' : 1.0, 'concat' : 1.0}\n",
    "latent_dim = 32\n",
    "channels = [9, 9]\n",
    "use_dropout = [False, False]\n",
    "patch_shape = curr_patch_shape\n",
    "scale = 1\n",
    "lesionsGen_model = Multimodel(\n",
    "    input_modalities, output_modalities, output_weights, latent_dim, channels, patch_shape, use_dropout, scale)\n",
    "lesionsGen_model.build()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false,
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "from keras.callbacks import EarlyStopping, ModelCheckpoint\n",
    "\n",
    "#patience = 10\n",
    "\n",
    "#stopper = EarlyStopping(patience=patience)\n",
    "checkpointer = ModelCheckpoint('models/model_WMHIGen_UsingVHISBISmoothed.h5', save_best_only=True, save_weights_only=True)\n",
    "\n",
    "N = len(in_train[modalities[0]])\n",
    "\n",
    "lesionsGen_model.model.fit(\n",
    "[in_train[modalities[0]], in_train[modalities[1]]],\n",
    "[out_train[modalities[0]],out_train[modalities[0]],out_train[modalities[0]],\n",
    " out_train[modalities[1]],out_train[modalities[1]],out_train[modalities[1]], \n",
    "np.empty((N, 2, 0)), np.empty((N, 1, 0))],\n",
    "validation_split=0.3, epochs=70,\n",
    "verbose=2,\n",
    "callbacks=[checkpointer])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "lesionsGen_model.model.load_weights('models/model_WMHIGen_UsingVHISBISmoothed.h5')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "##Testing on patient images (Using 8 WMHIMask)(Patients or Healthies)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "import os\n",
    "import sys\n",
    "import nibabel as nib\n",
    "%matplotlib inline\n",
    "\n",
    "#dataset path\n",
    "dataset_path = '/home/mostafasalem/AllData/New_Generator_VH/VSI_test_linear'\n",
    "#Masks patterns\n",
    "mask_pattern = dataset_path+'/{0}/W{1}.nii.gz'\n",
    "num_masks=8\n",
    "\n",
    "#Images patterns\n",
    "brainmask_pattern = dataset_path+'/{0}/brainmask.nii.gz'\n",
    "basalImg_pattern  = dataset_path+'/{0}/{1}_normalized_filled_WMHIM_smoothed.nii.gz'\n",
    "#basalImg_pattern  = dataset_path+'/{0}/{1}_filled_WMHIM_smoothed.nii.gz'\n",
    "\n",
    "generatedDir_pattern = dataset_path+'/{0}/generated_UsingVH' \n",
    "generatedImg_pattern = dataset_path+'/{0}/generated_UsingVH/{1}_gen.nii.gz' \n",
    "\n",
    "\n",
    "#Modalities &Step size & Patch shape\n",
    "#modalities=['t1','t2','pd','flair']\n",
    "#modalities=['T1', 'FLAIR']\n",
    "modalities=['t1', 'flair']\n",
    "step = (16, 16)\n",
    "curr_patch_shape = (64, 64)\n",
    "\n",
    "#Lesions and healthy cases\n",
    "testing_patients = sorted([f for f in os.listdir(dataset_path)])    \n",
    "\n",
    "#Train in&out data\n",
    "in_test={}\n",
    "\n",
    "#Reading the images\n",
    "for p in testing_patients:\n",
    "    print 'Reading case No. {} :'.format(p)\n",
    "    \n",
    "    if os.path.isfile(generatedImg_pattern.format(p, modalities[1])):\n",
    "            print '\\tCase no. {} is already computed...'.format(p)\n",
    "            continue  \n",
    "            \n",
    "    \n",
    "    generatedDir = generatedDir_pattern.format(p)\n",
    "    if not os.path.exists(generatedDir):\n",
    "        os.makedirs(generatedDir)\n",
    "    \n",
    "    \n",
    "    #Out volumes mask&affine    \n",
    "    out_vol_shape={}\n",
    "    out_vol_affine={}\n",
    "    \n",
    "    \n",
    "    #Read the brain mask in case of skull stripping\n",
    "    brainmask_filename = brainmask_pattern.format(p)    \n",
    "    brainmask = nib.load(brainmask_filename).get_data()    \n",
    "    brainmask=np.rollaxis(brainmask,2,0)    \n",
    "    brainmask_patches = extract_patches(brainmask, (1, ) + curr_patch_shape, (1, ) + step)\n",
    "    brainmask_patches = brainmask_patches.reshape((-1, 1, ) + curr_patch_shape)                \n",
    "    N = brainmask_patches.shape[0]    \n",
    "    del brainmask_patches\n",
    "    \n",
    "    # Reading the basal mask(s) that will be added as a second channel to all the modality encoders    \n",
    "    allmasks_patches = np.empty((N, 8, ) + curr_patch_shape)\n",
    "    print '\\tExtracting the mask patches'\n",
    "    for m in range(1,num_masks+1):        \n",
    "        mask_filename = mask_pattern.format(p,m)\n",
    "        mask = nib.load(mask_filename).get_data()\n",
    "        mask=np.rollaxis(mask,2,0)\n",
    "        mask_patches = extract_patches(mask, (1, ) + curr_patch_shape, (1, ) + step)        \n",
    "        mask_patches = mask_patches.reshape((-1, ) + curr_patch_shape)        \n",
    "        allmasks_patches[:, m-1] = mask_patches\n",
    "    \n",
    "    # The modalities encoder\n",
    "    print '\\tExtracting the modalities patches'\n",
    "    for m in modalities:\n",
    "        #Reading the basal modalities\n",
    "        print '\\t{0} basal patches'.format(m)\n",
    "        basalImg_filename = basalImg_pattern.format(p, m)\n",
    "        basalImg_data = nib.load(basalImg_filename)\n",
    "        basalImg = basalImg_data.get_data()\n",
    "        out_vol_affine[m] = basalImg_data.affine\n",
    "        basalImg=np.rollaxis(basalImg,2,0)                \n",
    "        out_vol_shape[m]=basalImg.shape        \n",
    "        #basalImg = (basalImg - basalImg.mean()) / basalImg.std()    \n",
    "        modality_patches = extract_patches(basalImg, (1, ) + curr_patch_shape, (1, ) + step)\n",
    "        modality_patches = modality_patches.reshape((-1, 1, ) + curr_patch_shape)                \n",
    "        in_test[m] = np.hstack((modality_patches, allmasks_patches))\n",
    "        del modality_patches        \n",
    "    print\n",
    "    del allmasks_patches        \n",
    "    \n",
    "    ## The prediction using the fake mask    \n",
    "    print '\\tThe prediction using the lesions mask '\n",
    "    preds = lesionsGen_model.model.predict([in_test[modalities[0]], in_test[modalities[1]]], verbose=2)            \n",
    "    for k,m in enumerate(modalities):\n",
    "        print '\\tSaving modality {0} at index {1}'.format(m, k*3 + 2)                \n",
    "        volume = perform_voting(preds[k*3 + 2].reshape((-1, 1, ) + curr_patch_shape), (1, ) + curr_patch_shape, out_vol_shape[m], (1, ) + step)\n",
    "        volume[brainmask==0]=0\n",
    "        volume = np.rollaxis(volume,0,3)\n",
    "        \n",
    "        nib.save(nib.Nifti1Image(volume, out_vol_affine[m]), generatedImg_pattern.format(p, m))                            \n",
    "    del preds"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 2",
   "language": "python",
   "name": "python2"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 2
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython2",
   "version": "2.7.15rc1"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
